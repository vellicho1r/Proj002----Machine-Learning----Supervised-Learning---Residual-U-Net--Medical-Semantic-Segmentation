# -*- coding: utf-8 -*-
"""ResUNet4mor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eOXmYRBADQj6_f0ypFlO_d2tcC4Tbte1
"""

import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
import matplotlib.pyplot as plt
import tifffile as tiff
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
from sklearn.model_selection import train_test_split
import os
import numpy as np
import random
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Concatenate

# Set the seed value
seed_value = 42

# 1. Set `PYTHONHASHSEED` environment variable at a fixed value
os.environ['PYTHONHASHSEED'] = str(seed_value)

# 2. Set `python` built-in pseudo-random generator at a fixed value
random.seed(seed_value)

# 3. Set `numpy` pseudo-random generator at a fixed value
np.random.seed(seed_value)

# 4. Set the `tensorflow` pseudo-random generator at a fixed value
tf.random.set_seed(seed_value)

!pip install nibabel

!pip install -U -q segmentation-models
!pip install -q tensorflow==2.2.1
!pip install -q keras==2.5
import os
os.environ["SM_FRAMEWORK"] = "tf.keras"

from tensorflow import keras
import segmentation_models as sm
!pip install segmentation-models
import tensorflow
import keras
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda, Activation
from tensorflow.keras import models, layers, regularizers
from tensorflow.keras import backend as K
import numpy as np
import nibabel as nib
import glob
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from datetime import datetime
from segmentation_models.losses import bce_jaccard_loss
from segmentation_models.losses import bce_dice_loss
from segmentation_models.losses import binary_focal_dice_loss
from keras.losses import binary_crossentropy
#from keras.losses import dice_ce
import keras.backend as K
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
#from res_unet_model import multi_unet_model
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
import random
import glob
from matplotlib import pyplot as plt
import keras
import numpy as np
import os
import math

"""**2. Importing Images and Masks from Google Drive**"""

from google.colab import drive
drive.mount('/content/drive')
# Set the base path
image_files = sorted(glob.glob(('/content/drive/MyDrive/image/*')))
label_files = sorted(glob.glob(('/content/drive/MyDrive/mask/*')))

# Check the number of images and labels gathered
print(f"Total images: {len(image_files)}")
print(f"Total labels: {len(label_files)}")

"""**3. Pre-process the images (Normalization to 255)**"""

from PIL import Image
import numpy as np
import tensorflow as tf

def preprocess_image(path):
    # Load the image using PIL library
    with Image.open(path) as img:
        # Convert the image to numpy array
        image = np.array(img)

    # If the image has more than one channel, extract just one channel
    if image.ndim > 2 and image.shape[2] > 1:
        image = image[..., 0]

    # Normalize the image to [0, 1] range
    image = image / 255.0

    # Convert image to a TensorFlow tensor
    image_tensor = tf.convert_to_tensor(image, dtype=tf.float32)

    # Add a channel dimension if it does not exist
    if image_tensor.ndim == 2:
        image_tensor = image_tensor[..., tf.newaxis]

    # Ensure image tensor is 3D at this point
    if image_tensor.ndim != 3:
        raise ValueError('Image tensor must be 3 dimensions [height, width, channels]')

    # Resize the image to the desired size
    image_tensor = tf.image.resize(image_tensor, [256, 256])

    return image_tensor

def preprocess_mask(path):
    # Load the mask using PIL library
    with Image.open(path) as mask_img:
        mask = np.array(mask_img)

    # If the mask has more than one channel, extract just one channel
    if mask.ndim > 2 and mask.shape[2] > 1:
        mask = mask[..., 0]

    # Normalize the mask to be in [0, 1]
    mask = mask / 255.0 if mask.max() > 1 else mask

    # Convert mask to a TensorFlow tensor
    mask_tensor = tf.convert_to_tensor(mask, dtype=tf.float32)

    # Add a channel dimension if it does not exist
    if mask_tensor.ndim == 2:
        mask_tensor = mask_tensor[..., tf.newaxis]

    # Ensure mask tensor is 3D at this point
    if mask_tensor.ndim != 3:
        raise ValueError('Mask tensor must be 3 dimensions [height, width, channels]')

    # Resize the mask to the desired size
    mask_tensor = tf.image.resize(mask_tensor, [256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)

    # The resize operation could push the values away from 0 and 1, we threshold to ensure it's a proper mask
    mask_tensor = tf.where(mask_tensor > 0.5, 1, 0)

    return mask_tensor

"""**Approximate Excecuting Time = (around) 4 minutes**"""

#Estimated Running time = 4 minutes

# Subset 10% of the dataset for quick experiments
subset_size = int(0.9 * len(image_files))
image_files_subset = image_files[:subset_size]
label_files_subset = label_files[:subset_size]

# Preprocess and load images into memory (This might take a lot of RAM, be careful with large datasets)
images = np.array([preprocess_image(f) for f in image_files_subset])
masks = np.array([preprocess_mask(f) for f in label_files_subset])

# Split into train and validation sets
X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.3, random_state=42)

"""**4. Define SegNet (Encoder + Decoder + Core)**"""

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose

def bn_act(x, act=True):
    x = tensorflow.keras.layers.BatchNormalization()(x)
    if act == True:
        x = tensorflow.keras.layers.Activation("relu")(x)
    return x

def conv_block(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    conv = bn_act(x)
    conv = tensorflow.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)
    return conv

def stem(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    conv = tensorflow.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)
    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)

    shortcut = tensorflow.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)
    shortcut = bn_act(shortcut, act=False)

    output = tensorflow.keras.layers.Add()([conv, shortcut])
    return output

def residual_block(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)
    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)

    shortcut = tensorflow.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)
    shortcut = bn_act(shortcut, act=False)

    output = tensorflow.keras.layers.Add()([shortcut, res])
    return output

def upsample_concat_block(x, xskip):
    u = tensorflow.keras.layers.UpSampling2D((2, 2))(x)
    c = tensorflow.keras.layers.Concatenate()([u, xskip])
    return c


def ResUNet():
    f = [16, 32, 64, 128, 256]
    inputs = tensorflow.keras.layers.Input((256, 256, 1))

    ## Encoder
    e0 = inputs
    e1 = stem(e0, f[0])
    e2 = residual_block(e1, f[1], strides=2)
    e3 = residual_block(e2, f[2], strides=2)
    e4 = residual_block(e3, f[3], strides=2)
    e5 = residual_block(e4, f[4], strides=2)

    ## Bridge
    b0 = conv_block(e5, f[4], strides=1)
    b1 = conv_block(b0, f[4], strides=1)

    ## Decoder
    u1 = upsample_concat_block(b1, e4)
    d1 = residual_block(u1, f[4])

    u2 = upsample_concat_block(d1, e3)
    d2 = residual_block(u2, f[3])

    u3 = upsample_concat_block(d2, e2)
    d3 = residual_block(u3, f[2])

    u4 = upsample_concat_block(d3, e1)
    d4 = residual_block(u4, f[1])

    outputs = tensorflow.keras.layers.Conv2D(1, (1, 1), padding="same", activation="sigmoid")(d4)
    model = tensorflow.keras.models.Model(inputs, outputs)
    return model

# Compile the model
model = ResUNet()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

"""**5. Define Evaluation Metrics (DSC, IOU)**"""

from keras import backend as K
from keras.losses import binary_crossentropy
import tensorflow as tf

def dice_coef(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def iou_coef(y_true, y_pred, smooth=1):
  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])
  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection
  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)
  return iou

def dice_loss(y_true, y_pred):
    smooth = 1.
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = y_true_f * y_pred_f
    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
    return 1. - score

def bce_dice_loss(y_true, y_pred):
    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)

"""**6. Define EarlyStopping and Compile the model**"""

from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard

# Early Stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)

# Learning Rate Scheduler
def lr_scheduler(epoch, lr):
    decay_rate = 0.1
    decay_step = 30
    if epoch % decay_step == 0 and epoch:
        return lr * decay_rate
    return lr

lr_scheduler = LearningRateScheduler(lr_scheduler, verbose=1)

# ModelCheckpoint
checkpoint_path = "/kaggle/working/model_checkpoint.h5"
model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True)

# Adjust the input shape to match your dataset (height, width, channels)
input_img = Input((256, 256, 1), name='img')

model.compile(optimizer = 'adam', loss = bce_dice_loss, metrics = [dice_coef,iou_coef, 'acuracy'])

model.summary()

import os
from keras.models import load_model

checkpoint_path = "/kaggle/working/model_checkpoint.h5"


# Function to create a new model instance
def create_model():
    input_img = Input((256, 256, 1), name='img')

    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef, iou_coef, 'accuracy'])
    return model

# Check if a checkpoint exists
if os.path.exists(checkpoint_path):
    print("Loading model from checkpoint")
    model = load_model(checkpoint_path, custom_objects={'bce_dice_loss': bce_dice_loss,
                                                         'dice_coef': dice_coef,
                                                         'iou_coef': iou_coef})

    print("Model Loaded from Checkpoint")
else:
    print("Creating a new model")
    model = create_model()

"""**7. Fit the Model**"""

from keras.callbacks import Callback    #Because Callback was not defined

from keras.layers import Add    #Because of the NameError : name 'Add' is not defined

from keras.layers import Multiply #Same for Multiply

from tensorflow.keras.layers import Conv2D, MaxPool2D
#Because of the Error : NameError: name 'MaxPool2D' is not defined

from IPython.display import clear_output    #Because of the Error : NameError: name 'clear_output' is not defined

!pip install tensorflow_addons
!pip install keras
!pip install segmentation-models
!pip install tf_explain
clear_output()

!pip install tensorflow_addons

import tensorflow_addons as tfa

from tf_explain.core.grad_cam import GradCAM
#Because of the Error NameError: name 'GradCAM' is not defined

exp = GradCAM()

class ShowProgress(Callback):
    def on_epoch_end(self, epochs, logs=None):
        id = np.random.randint(200)
        image = images[id]
        mask = masks[id]
        pred_mask = self.model.predict(image[np.newaxis,...])
        cam = exp.explain(
            validation_data=(image[np.newaxis,...], mask),
            class_index=1,
            model=self.model
        )
        plt.figure(figsize=(10,5))

        plt.subplot(1,2,1)
        plt.title("Original Mask")
        show_mask_only(mask, cmap='gray')

        plt.subplot(1,2,2)
        plt.title("Predicted Mask")
        show_mask_only(pred_mask, cmap='gray')

        plt.tight_layout()
        plt.show()

# Callbacks
cb = [
    # EarlyStopping(patience=3, restore_best_weight=True), # With Segmentation I trust on eyes rather than on metrics
    ModelCheckpoint("AttentionCustomUNet.h5", save_best_only=True),
    ShowProgress()
]

def show_mask_only(mask, cmap=None, alpha=0.4):
    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)
    plt.axis('off')

def load_image(image, SIZE):
    return np.round(resize(img_to_array(load_img(image))/255.,(SIZE, SIZE)),4)

SIZE = 128

def load_images(image_paths, SIZE, mask=False, trim=None):
    if trim is not None:
        image_paths = image_paths[:trim]

    if mask:
        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 1))
    else:
        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 3))

    for i,image in enumerate(image_paths):
        img = load_image(image,SIZE)
        if mask:
            images[i] = img[:,:,:1]
        else:
            images[i] = img

    return images

# Train the model
# Assume 'train_images', 'train_masks', 'val_images', and 'val_masks' are already loaded and preprocessed as per previous steps
results = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=60,
    validation_data=(X_val, y_val),
    callbacks=cb
)

#Because of the Error : NameError: name 'get_mask_box' is not defined

import cv2
import numpy as np

def get_mask_box(mask):
    img = np.uint8(mask[0, :, :, 0] * 255)

    _, binary = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        color = (0, 255, 0)
        cv2.rectangle(img_bgr, (x, y), (x + w, y + h), color, 2)

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.5
        thickness = 1
        text_height = f'Height: {h}'
        text_width = f'Width: {w}'
        text_height_size = cv2.getTextSize(text_height, font, font_scale, thickness)[0]
        text_width_size = cv2.getTextSize(text_width, font, font_scale, thickness)[0]
        cv2.putText(img_bgr, text_height, (x, y - text_height_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)
        cv2.putText(img_bgr, text_width, (x + w - text_width_size[0], y + h + text_width_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)

    plt.imshow(img_bgr,cmap = None)
    plt.axis('off')

id = 11
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

id = 12
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

id = 66
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

id = 67
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

id = 85
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

id = 86
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

id = 193
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

id = 194
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

import cv2
import numpy as np

def get_mask_box(mask):
    img = np.uint8(mask[0, :, :, 0] * 255)

    _, binary = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        color = (0, 255, 0)
        cv2.rectangle(img_bgr, (x, y), (x + w, y + h), color, 2)

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.5
        thickness = 1
        text_height = f'Height: {h}'
        text_width = f'Width: {w}'
        text_height_size = cv2.getTextSize(text_height, font, font_scale, thickness)[0]
        text_width_size = cv2.getTextSize(text_width, font, font_scale, thickness)[0]
        cv2.putText(img_bgr, text_height, (x, y - text_height_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)
        cv2.putText(img_bgr, text_width, (x + w - text_width_size[0], y + h + text_width_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)

    plt.imshow(img_bgr,cmap = None)
    plt.axis('off')

plt.figure(figsize=(20,25))
n=0
for i in range(1,(5*3)+1):
    plt.subplot(5,3,i)
    if n==0:
        id = np.random.randint(len(images))
        image = images[id]
        mask = masks[id]
        pred_mask = model.predict(image[np.newaxis,...])

        plt.title("Original Mask")
        show_mask(image, mask)
        n+=1
    elif n==1:
        plt.title("Predicted Mask")
        show_mask(image, pred_mask)
        n+=1
    elif n==2:
        pred_mask = (pred_mask>0.5).astype('float')
        plt.title("Processed Mask")
        show_mask(image, pred_mask)
        n=0
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Assuming you have the history object containing the accuracies
# history = some_model.fit(...)

# Calculating the area under the curve
train_acc = history['accuracy']
val_acc = history['val_accuracy']
epochs = range(1, len(train_acc) + 1)

train_auc = np.trapz(train_acc, x=epochs)
val_auc = np.trapz(val_acc, x=epochs)

# Plotting Training and Validation Accuracy
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)

plt.plot(epochs, train_acc, label='Training Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.fill_between(epochs, train_acc, alpha=0.4)
plt.fill_between(epochs, val_acc, alpha=0.4)

plt.title('Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.figtext(0.5,0.5,f'Training AUC: {train_auc:.2f}\nValidation AUC: {val_auc:.2f}', fontsize=12, ha='center')
plt.show()

import matplotlib.pyplot as plt

# Extract the history from the results
history = results.history

# Plotting Training and Validation Loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history['loss'], label='Training Loss')
plt.plot(history['val_loss'], label='Validation Loss')
plt.title('ResU-Net model Loss Over Epochs')
plt.xlabel('Number of Epochs')
plt.ylabel('Loss')
plt.legend()

# Plotting Training and Validation Loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history['accuracy'], label='Training Accuracy')
plt.plot(history['val_accuracy'], label='Validation Accuracy')
plt.title('ResU-Net model Accuracy Over Epochs')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plotting Training and Validation Dice Coefficient
plt.subplot(1, 2, 2)
plt.plot(history['dice_coef'], label='Train Dice Coefficient')
plt.plot(history['val_dice_coef'], label='Validation Dice Coefficient')
plt.title('ResU-Net model Dice Coefficient Over Epochs')
plt.xlabel('Number of Epochs')
plt.ylabel('Dice Coefficient')
plt.legend()

plt.show()

# Plotting Training and Validation IoU Coefficient
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history['iou_coef'], label='Train IoU Coefficient')
plt.plot(history['val_iou_coef'], label='Validation IoU Coefficient')
plt.title('ResU-Net model IoU Coefficient Over Epochs')
plt.xlabel('Number of Epochs')
plt.ylabel('IoU Coefficient')
plt.legend()

plt.show()